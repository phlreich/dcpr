{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI0AhNmWmu_b",
        "outputId": "314e60f3-1fb8-4a16-8925-1be255405242"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting Overview_and_Clustering.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile Overview_and_Clustering.py \n",
        "import streamlit as st \n",
        "\n",
        "import pacmap as pm\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn import metrics\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import statistics\n",
        "import sys\n",
        "import os\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "st.set_option('deprecation.showPyplotGlobalUse', False)\n",
        "\n",
        "imputation_feats = ['slope', 'exang', 'restecg', 'fbs', 'cp']\n",
        "\n",
        "def delete_with_probability(val):\n",
        "    if randint(0, 100) <= 5:\n",
        "        val = np.NAN\n",
        "    return val\n",
        "\n",
        "\n",
        "def delete_random_values(df: pd.DataFrame):\n",
        "    \"\"\"Delete values in given columns randomly with probability 0.05\"\"\"\n",
        "    cols = ['slope', 'exang', 'restecg', 'fbs', 'cp']\n",
        "    for col in cols:\n",
        "        df[col] = df[col].apply(delete_with_probability)\n",
        "    return df\n",
        "    \n",
        "def impute_mean(df: pd.DataFrame):\n",
        "    \"\"\"Replace NAN with mean of column\"\"\"\n",
        "    for feat in imputation_feats:\n",
        "        mean = df[feat].mean()\n",
        "        df[feat] = df[feat].fillna(mean)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def impute_median(df: pd.DataFrame):\n",
        "    \"\"\"Replace NAN with median of column\"\"\"\n",
        "    for feat in imputation_feats:\n",
        "        mean = df[feat].median()\n",
        "        df[feat] = df[feat].fillna(mean)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def impute_listwise_deletion(df: pd.DataFrame):\n",
        "    \"\"\"Remove a row where at least one value is NAN\"\"\"\n",
        "    return df.dropna()\n",
        "\n",
        "def get_silhouette_coefficient(X, kmeans, metric='euclidean'):\n",
        "    \"\"\"Silhouette Coefficient for kmeans clustering\"\"\"\n",
        "    labels = kmeans.labels_\n",
        "    st.write(\"Silhouette Coefficient (The higher the score the better the clustering [0,1]; -1 invalid cluster):\")\n",
        "    if max(labels) < 1:\n",
        "        return st.write(\"Choose at least k=2 to get a valid coefficient!\")\n",
        "    else:\n",
        "        coefficient = metrics.silhouette_score(X, labels, metric=metric)\n",
        "        return st.write(coefficient)\n",
        "\n",
        "def get_davies_bouldin_score(X, kmeans):\n",
        "    labels = kmeans.labels_\n",
        "    st.write(\"Davies Bouldin Score (The lower the better):\")\n",
        "    if max(labels) < 1:\n",
        "        return st.write(\"Choose at least k=2 to get a valid score!\")\n",
        "    else:\n",
        "        score = metrics.davies_bouldin_score(X, labels)\n",
        "        return st.write(score)\n",
        "\n",
        "df = pd.read_csv(\"data/heart.csv\")\n",
        "\n",
        "\n",
        "st.title('Heart Disease Dataset')\n",
        "st.text(\"\"\"This data set dates from 1988 and consists of four databases:\\n\n",
        "Cleveland, Hungary, Switzerland, and Long Beach V. It contains 76 attributes,\\n\n",
        "including the predicted attribute, but all published experiments refer to using\\n\n",
        "a subset of 14 of them with 1025 entries. The \"target\" field refers to the presence\\n\n",
        "of heart disease in the patient. It is integer valued 0 = no disease and 1 = disease.\"\"\")\n",
        "st.write('Attributes:')\n",
        "st.write('1. age')\n",
        "st.write('2. sex')\n",
        "st.write('3. cp: chest pain type (4 values)')\n",
        "st.write('4. trestbps: resting blood pressure (in mm Hg on admission to the hospital)')\n",
        "st.write('5. chol: serum cholestoral in mg/dl')\n",
        "st.write('6. fbs: fasting blood sugar > 120 mg/dl')\n",
        "st.write('7. restecg: resting electrocardiographic results (values 0,1,2)')\n",
        "st.write('8. thalach: maximum heart rate achieved')\n",
        "st.write('9. exang: exercise induced angina')\n",
        "st.write('10. oldpeak: ST depression induced by exercise relative to rest')\n",
        "st.write('11. slope: the slope of the peak exercise ST segment')\n",
        "st.write('12. ca: number of major vessels (0-3) colored by flourosopy')\n",
        "st.write('13. thal: 0 = normal; 1 = fixed defect; 2 = reversable defect')\n",
        "st.write('14. target: 1 = disease; 0 = no disease')\n",
        "\n",
        "\n",
        "st.subheader('Dataset sample:')\n",
        "# st.dataframe(df.sample(10))  # Same as st.write(df)\n",
        "df\n",
        "\n",
        "######\n",
        "# Fixing the Data Types\n",
        "mis_features=['thal','ca','slope','exang','restecg','fbs','cp','sex']\n",
        "df[mis_features] = df[mis_features].astype(object)\n",
        "\n",
        "#Split numerical-categorical Features\n",
        "numerical_col = df.select_dtypes(exclude=np.object_)\n",
        "categorical_col = df.select_dtypes(exclude=np.number)\n",
        "######\n",
        "\n",
        "st.subheader('Dataset visualization:')\n",
        "# plot of crosstab histograms\n",
        "st.text('Relationship between sex and presence of a heart disease:')\n",
        "fig1 = plt.figure(figsize = (6,6))\n",
        "pd.crosstab(df.target, df.sex).plot(kind=\"bar\", figsize=(6, 6))\n",
        "plt.xlabel(\"0 = No Disease \\n 1 = Disease\")\n",
        "plt.xticks(rotation=360)\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.legend([\"Female\", \"Male\"])\n",
        "fig1 = plt.show()\n",
        "#fig1 = plt.figure()\n",
        "st.pyplot(fig1)\n",
        "##################\n",
        "\n",
        "# correlation matrix plot\n",
        "st.text('Correlation matrix of the attributes:')\n",
        "correlation_matrix = df.corr()\n",
        "fig2 = plt.figure(figsize = (10,6))\n",
        "sns.heatmap(correlation_matrix, annot = True, cmap=\"YlGnBu\")\n",
        "st.pyplot(fig2)           \n",
        "##################\n",
        "\n",
        "# attribute and target frequency plot\n",
        "st.text('Relationship between each attribute and the presence of a heart disease:')\n",
        "cat_col=categorical_col.columns\n",
        "fig3 = plt.figure(figsize=(12,12))\n",
        "for index in range(len(cat_col)):\n",
        "    if cat_col[index] != 'target':\n",
        "        plt.subplot(4,2,index + 1)\n",
        "        sns.countplot(data = categorical_col,x=cat_col[index],hue=df['target'], palette =\"viridis\")\n",
        "        plt.xlabel(cat_col[index].upper(),fontsize=12)\n",
        "        plt.ylabel(\"count\", fontsize=12)\n",
        "        plt.subplots_adjust(wspace = 0.3, hspace= 0.3)\n",
        "st.pyplot(fig3)\n",
        "\n",
        "\n",
        "############################################################################\n",
        "\n",
        "variable_list = [\"1. age\",\n",
        "\"2. sex\",\n",
        "\"3. cp: chest pain type (4 values)\",\n",
        "\"4. trestbps: resting blood pressure (in mm Hg on admission to the hospital)\",\n",
        "\"5. chol: serum cholestoral in mg/dl\",\n",
        "\"6. fbs: fasting blood sugar > 120 mg/dl\",\n",
        "\"7. restecg: resting electrocardiographic results (values 0,1,2)\",\n",
        "\"8. thalach: maximum heart rate achieved\",\n",
        "\"9. exang: exercise induced angina\",\n",
        "\"10. oldpeak: ST depression induced by exercise relative to rest\",\n",
        "\"11. slope: the slope of the peak exercise ST segment\",\n",
        "\"12. ca: number of major vessels (0-3) colored by flourosopy\",\n",
        "\"13. thal: 0 = normal; 1 = fixed defect; 2 = reversable defect\",\n",
        "\"14. target: 1 = disease; 0 = no disease\",]\n",
        "\n",
        "vars = st.multiselect('Select the attributes to include in the clustering:',\n",
        "    variable_list,\n",
        "    default=variable_list)\n",
        "\n",
        "#st.write('You selected:', vars)\n",
        "\n",
        "vars = [True if i in vars else False for i in variable_list]\n",
        "\n",
        "select_sex = st.select_slider(\"\",options=[\"both sexes included\", \"only male\", \"only female\",])\n",
        "\n",
        "if select_sex != \"both sexes included\":\n",
        "    if select_sex == \"only female\": \n",
        "        select_sex = 0\n",
        "    else:\n",
        "        select_sex = 1\n",
        "    df = df[df[\"sex\"] == select_sex]\n",
        "\n",
        "\n",
        "categorical = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal', 'target']\n",
        "categorical = [i for i in categorical if i in df.columns]\n",
        "one_hot_encode = st.checkbox('One-hot encode categorical features', value=True)\n",
        "if one_hot_encode:\n",
        "    pd.get_dummies(df, columns=categorical)\n",
        "\n",
        "min_max_normalize = st.checkbox('Min-max normalize numerical features', value=True)\n",
        "if min_max_normalize:\n",
        "    columns_to_normalize = [i for i in df.columns if i not in categorical]\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    scaler = MinMaxScaler()\n",
        "    df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############# Task2: clusters ###################\n",
        "\n",
        "k = st.slider('Number of k-means clusters:', 1, 10, 2)\n",
        "\n",
        "kmeans = KMeans(n_clusters=k, random_state=0).fit(df.to_numpy()[:,vars])\n",
        "\n",
        "\n",
        "# DBSCAN\n",
        "from sklearn.cluster import DBSCAN \n",
        "eps = st.slider('DBSCAN eps:', 0.0, 2.0, 0.5)\n",
        "min_samples = st.slider('DBSCAN min_samples:', 1, 10, 1)\n",
        "dbscan = DBSCAN(eps=eps, min_samples=min_samples).fit(df.to_numpy()[:,vars])\n",
        "\n",
        "\n",
        "############## Choose coloring scheme\n",
        "\n",
        "coloring_name = st.selectbox('Select data coloring scheme:', [\"target\", \"sex\", \"KMEANS cluster\", \"DBSCAN cluster\"])\n",
        "\n",
        "if coloring_name == \"KMEANS cluster\":\n",
        "    coloring = kmeans.labels_\n",
        "elif coloring_name == \"target\":\n",
        "    coloring = df.target\n",
        "elif coloring_name == \"DBSCAN cluster\":\n",
        "    coloring = dbscan.labels_\n",
        "else:\n",
        "    coloring = df.sex\n",
        "\n",
        "############# t-sne ############################\n",
        "\n",
        "X_embedded = TSNE(n_components=2, learning_rate='auto', init='pca', perplexity=3).fit_transform(df.to_numpy())\n",
        "tsne_plot = plt.figure()\n",
        "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=coloring)\n",
        "plt.title(\"t-SNE, coloring:\" + coloring_name)\n",
        "st.pyplot(tsne_plot)\n",
        "\n",
        "#st.write(\"K-means scores:\")\n",
        "st.markdown(\"<h4 style='text-align: center; '>K-means scores:</h4>\", unsafe_allow_html=True)\n",
        "get_silhouette_coefficient(X_embedded, kmeans)\n",
        "get_davies_bouldin_score(X_embedded, kmeans)\n",
        "\n",
        "#st.write(\"DBSCAN scores:\")\n",
        "st.markdown(\"<h4 style='text-align: center; '>DBSCAN scores:</h4>\", unsafe_allow_html=True)\n",
        "get_silhouette_coefficient(X_embedded, dbscan)\n",
        "get_davies_bouldin_score(X_embedded, dbscan)\n",
        "\n",
        "###################### PACMAP ########################\n",
        "\n",
        "# create pacmap object\n",
        "pac = pm.PaCMAP()\n",
        "# fit pacmap\n",
        "reduced = pac.fit_transform(df.to_numpy(), init=\"pca\")\n",
        "# plot\n",
        "figpm, axpm = plt.subplots(1, 1, figsize=(6, 6))\n",
        "axpm.scatter(reduced[:, 0], reduced[:, 1], c=coloring)\n",
        "axpm.set_title(\"PaCMAP, coloring: \" + coloring_name)\n",
        "st.pyplot(figpm)\n",
        "\n",
        "#st.write(\"K-means scores:\")\n",
        "st.markdown(\"<h4 style='text-align: center; '>K-means scores:</h4>\", unsafe_allow_html=True)\n",
        "get_silhouette_coefficient(reduced, kmeans)\n",
        "get_davies_bouldin_score(reduced, kmeans)\n",
        "\n",
        "#st.write(\"DBSCAN scores:\")\n",
        "st.markdown(\"<h4 style='text-align: center; '>DBSCAN scores:</h4>\", unsafe_allow_html=True)\n",
        "get_silhouette_coefficient(reduced, dbscan)\n",
        "get_davies_bouldin_score(reduced, dbscan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "e620dad3c9634dfc2a751b8e6b95fbe1a1bce11138fae698449987138f801104"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
